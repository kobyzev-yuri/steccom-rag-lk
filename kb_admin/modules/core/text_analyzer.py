"""
Text Structure Analyzer
–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Ä–∞–∑–±–∏–µ–Ω–∏—è –Ω–∞ —á–∞–Ω–∫–∏
"""

import re
from typing import Dict, List, Tuple, Any
from dataclasses import dataclass
from pathlib import Path


@dataclass
class TextStructure:
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç–µ–∫—Å—Ç–∞"""
    total_length: int
    paragraph_count: int
    section_count: int
    average_paragraph_length: float
    has_numbered_sections: bool
    has_bullet_points: bool
    language: str
    complexity_score: float
    recommended_chunk_size: int
    recommended_overlap: int


class TextAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ç–µ–∫—Å—Ç–∞"""
    
    def __init__(self):
        self.section_patterns = [
            r'^\d+\.\s+',  # 1. –ó–∞–≥–æ–ª–æ–≤–æ–∫
            r'^\d+\.\d+\s+',  # 1.1 –ü–æ–¥–∑–∞–≥–æ–ª–æ–≤–æ–∫
            r'^[IVX]+\.\s+',  # I. –†–∏–º—Å–∫–∏–µ —Ü–∏—Ñ—Ä—ã
            r'^[–ê-–Ø][–∞-—è]+\s+\d+\.',  # –†–∞–∑–¥–µ–ª 1.
            r'^–ì–ª–∞–≤–∞\s+\d+',  # –ì–ª–∞–≤–∞ 1
            r'^–ß–∞—Å—Ç—å\s+\d+',  # –ß–∞—Å—Ç—å 1
        ]

    # –ó–∞–≥–ª—É—à–∫–∏ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å –º–µ–Ω–µ–¥–∂–µ—Ä–æ–º –º–æ–¥–µ–ª–µ–π UI
    def get_chat_backend_info(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Å—Ç—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é, —Ç.–∫. –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç LLM –Ω–∞–ø—Ä—è–º—É—é."""
        return {"provider": "n/a", "model": "n/a"}

    def set_chat_backend(self, provider: str, model: str, **kwargs) -> None:
        """–ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º, —Ç.–∫. –º–æ–¥—É–ª—å –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç LLM –Ω–∞–ø—Ä—è–º—É—é."""
        return
        
        self.bullet_patterns = [
            r'^[-‚Ä¢*]\s+',  # - –ø—É–Ω–∫—Ç
            r'^\d+\)\s+',  # 1) –ø—É–Ω–∫—Ç
            r'^[–∞-—è]\)\s+',  # –∞) –ø—É–Ω–∫—Ç
        ]
    
    def analyze_text_structure(self, text: str) -> TextStructure:
        """–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ç–µ–∫—Å—Ç–∞"""
        if not text or not text.strip():
            return self._get_default_structure()
        
        # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        total_length = len(text)
        paragraphs = [p.strip() for p in text.split('\n\n') if p.strip()]
        paragraph_count = len(paragraphs)
        
        # –ê–Ω–∞–ª–∏–∑ —Å–µ–∫—Ü–∏–π
        sections = self._find_sections(text)
        section_count = len(sections)
        has_numbered_sections = section_count > 0
        
        # –ê–Ω–∞–ª–∏–∑ —Å–ø–∏—Å–∫–æ–≤
        has_bullet_points = self._has_bullet_points(text)
        
        # –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞
        if paragraph_count > 0:
            avg_paragraph_length = sum(len(p) for p in paragraphs) / paragraph_count
        else:
            avg_paragraph_length = 0
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —è–∑—ã–∫–∞
        language = self._detect_language(text)
        
        # –û—Ü–µ–Ω–∫–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        complexity_score = self._calculate_complexity(text, paragraphs, sections)
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —á–∞–Ω–∫–∞–º
        recommended_chunk_size, recommended_overlap = self._recommend_chunk_settings(
            total_length, paragraph_count, section_count, avg_paragraph_length, complexity_score
        )
        
        return TextStructure(
            total_length=total_length,
            paragraph_count=paragraph_count,
            section_count=section_count,
            average_paragraph_length=avg_paragraph_length,
            has_numbered_sections=has_numbered_sections,
            has_bullet_points=has_bullet_points,
            language=language,
            complexity_score=complexity_score,
            recommended_chunk_size=recommended_chunk_size,
            recommended_overlap=recommended_overlap
        )
    
    def _find_sections(self, text: str) -> List[Tuple[int, str]]:
        """–ü–æ–∏—Å–∫ —Å–µ–∫—Ü–∏–π –≤ —Ç–µ–∫—Å—Ç–µ"""
        sections = []
        lines = text.split('\n')
        
        for i, line in enumerate(lines):
            line = line.strip()
            if not line:
                continue
                
            for pattern in self.section_patterns:
                if re.match(pattern, line):
                    sections.append((i, line))
                    break
        
        return sections
    
    def _has_bullet_points(self, text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Å–ø–∏—Å–∫–æ–≤"""
        lines = text.split('\n')
        bullet_count = 0
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            for pattern in self.bullet_patterns:
                if re.match(pattern, line):
                    bullet_count += 1
                    break
        
        return bullet_count > 2  # –ï—Å–ª–∏ –±–æ–ª—å—à–µ 2 –ø—É–Ω–∫—Ç–æ–≤, —Å—á–∏—Ç–∞–µ–º —á—Ç–æ –µ—Å—Ç—å —Å–ø–∏—Å–æ–∫
    
    def _detect_language(self, text: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —è–∑—ã–∫–∞ —Ç–µ–∫—Å—Ç–∞"""
        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ/–∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ
        cyrillic_chars = len(re.findall(r'[–∞-—è—ë]', text.lower()))
        latin_chars = len(re.findall(r'[a-z]', text.lower()))
        
        if cyrillic_chars > latin_chars:
            return 'ru'
        elif latin_chars > cyrillic_chars:
            return 'en'
        else:
            return 'mixed'
    
    def _calculate_complexity(self, text: str, paragraphs: List[str], sections: List[Tuple[int, str]]) -> float:
        """–†–∞—Å—á–µ—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞ (0.0 - 1.0)"""
        complexity = 0.0
        
        # –§–∞–∫—Ç–æ—Ä –¥–ª–∏–Ω—ã
        if len(text) > 10000:
            complexity += 0.3
        elif len(text) > 5000:
            complexity += 0.2
        elif len(text) > 1000:
            complexity += 0.1
        
        # –§–∞–∫—Ç–æ—Ä –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤
        if len(paragraphs) > 20:
            complexity += 0.2
        elif len(paragraphs) > 10:
            complexity += 0.1
        
        # –§–∞–∫—Ç–æ—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏
        if len(sections) > 5:
            complexity += 0.2
        elif len(sections) > 2:
            complexity += 0.1
        
        # –§–∞–∫—Ç–æ—Ä —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤
        technical_terms = len(re.findall(r'\b(?:API|SQL|HTTP|TCP|IP|JSON|XML|PDF|DOC|XLS)\b', text, re.IGNORECASE))
        if technical_terms > 10:
            complexity += 0.2
        elif technical_terms > 5:
            complexity += 0.1
        
        return min(1.0, complexity)
    
    def _recommend_chunk_settings(self, total_length: int, paragraph_count: int, 
                                section_count: int, avg_paragraph_length: float, 
                                complexity_score: float) -> Tuple[int, int]:
        """–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º —á–∞–Ω–∫–æ–≤"""
        
        # –ë–∞–∑–æ–≤—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        base_chunk_size = 600
        base_overlap = 100
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        if section_count > 0:
            # –ï—Å–ª–∏ –µ—Å—Ç—å —Å–µ–∫—Ü–∏–∏, –¥–µ–ª–∞–µ–º —á–∞–Ω–∫–∏ –º–µ–Ω—å—à–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            base_chunk_size = 500
            base_overlap = 120
        elif avg_paragraph_length > 1000:
            # –ï—Å–ª–∏ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã –¥–ª–∏–Ω–Ω—ã–µ, —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º —á–∞–Ω–∫–∏
            base_chunk_size = 800
            base_overlap = 150
        elif avg_paragraph_length < 200:
            # –ï—Å–ª–∏ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã –∫–æ—Ä–æ—Ç–∫–∏–µ, —É–º–µ–Ω—å—à–∞–µ–º —á–∞–Ω–∫–∏
            base_chunk_size = 400
            base_overlap = 80
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        if complexity_score > 0.7:
            # –°–ª–æ–∂–Ω—ã–π —Ç–µ–∫—Å—Ç - –±–æ–ª—å—à–µ –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ
            base_overlap = int(base_overlap * 1.5)
        elif complexity_score < 0.3:
            # –ü—Ä–æ—Å—Ç–æ–π —Ç–µ–∫—Å—Ç - –º–µ–Ω—å—à–µ –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ
            base_overlap = int(base_overlap * 0.7)
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—â–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
        if total_length > 50000:
            # –ë–æ–ª—å—à–æ–π –¥–æ–∫—É–º–µ–Ω—Ç - –±–æ–ª—å—à–µ —á–∞–Ω–∫–∏
            base_chunk_size = int(base_chunk_size * 1.2)
        elif total_length < 5000:
            # –ú–∞–ª–µ–Ω—å–∫–∏–π –¥–æ–∫—É–º–µ–Ω—Ç - –º–µ–Ω—å—à–µ —á–∞–Ω–∫–∏
            base_chunk_size = int(base_chunk_size * 0.8)
        
        return base_chunk_size, base_overlap
    
    def _get_default_structure(self) -> TextStructure:
        """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è –ø—É—Å—Ç–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"""
        return TextStructure(
            total_length=0,
            paragraph_count=0,
            section_count=0,
            average_paragraph_length=0.0,
            has_numbered_sections=False,
            has_bullet_points=False,
            language='unknown',
            complexity_score=0.0,
            recommended_chunk_size=600,
            recommended_overlap=100
        )
    
    def get_analysis_summary(self, structure: TextStructure) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞"""
        summary = f"""
üìä –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ç–µ–∫—Å—Ç–∞:
‚Ä¢ –û–±—â–∞—è –¥–ª–∏–Ω–∞: {structure.total_length:,} —Å–∏–º–≤–æ–ª–æ–≤
‚Ä¢ –ü–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤: {structure.paragraph_count}
‚Ä¢ –°–µ–∫—Ü–∏–π: {structure.section_count}
‚Ä¢ –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞: {structure.average_paragraph_length:.0f} —Å–∏–º–≤–æ–ª–æ–≤
‚Ä¢ –Ø–∑—ã–∫: {structure.language}
‚Ä¢ –°–ª–æ–∂–Ω–æ—Å—Ç—å: {structure.complexity_score:.2f}/1.0

üéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:
‚Ä¢ –†–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞: {structure.recommended_chunk_size}
‚Ä¢ –ü–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ: {structure.recommended_overlap}
‚Ä¢ –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å: {'–í—ã—Å–æ–∫–∞—è' if structure.has_numbered_sections else '–ù–∏–∑–∫–∞—è'}
‚Ä¢ –°–ø–∏—Å–∫–∏: {'–ï—Å—Ç—å' if structure.has_bullet_points else '–ù–µ—Ç'}
        """
        return summary.strip()
