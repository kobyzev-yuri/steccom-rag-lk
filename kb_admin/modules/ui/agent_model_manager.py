"""
Agent Model Manager UI Component
–ö–æ–º–ø–æ–Ω–µ–Ω—Ç –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –º–æ–¥–µ–ª—è–º–∏ –∞–≥–µ–Ω—Ç–æ–≤ –≤ KB Admin
"""

import streamlit as st
import subprocess
import os
from typing import Dict, List, Optional
import logging

logger = logging.getLogger(__name__)

class AgentModelManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –º–æ–¥–µ–ª–µ–π –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤ KB Admin"""
    
    def __init__(self):
        self.available_ollama_models = self._get_ollama_models()
    
    def _get_ollama_models(self) -> List[str]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π Ollama"""
        try:
            result = subprocess.run(['ollama', 'list'], capture_output=True, text=True, timeout=10)
            if result.returncode == 0:
                lines = result.stdout.strip().split('\n')[1:]  # Skip header
                models = []
                for line in lines:
                    if line.strip():
                        model_name = line.split()[0]  # Get first column (model name)
                        models.append(model_name)
                return models
            else:
                logger.error("–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è ollama list")
                return []
        except subprocess.TimeoutExpired:
            logger.error("–¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π")
            return []
        except FileNotFoundError:
            logger.error("Ollama –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return []
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π: {e}")
            return []
    
    def render_agent_model_config(self, agent_name: str, agent_instance, key_prefix: str = ""):
        """–û—Ç–æ–±—Ä–∞–∑–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞"""
        st.subheader(f"ü§ñ {agent_name} - –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–µ–∫—É—â—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        current_config = agent_instance.get_chat_backend_info()
        if current_config:
            col1, col2 = st.columns(2)
            with col1:
                st.info(f"**–¢–µ–∫—É—â–∏–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä:** {current_config.get('provider', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}")
            with col2:
                st.info(f"**–¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å:** {current_config.get('model', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}")
        
        # –í—ã–±–æ—Ä –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Ç–µ–∫—É—â–∏–π)
        providers = ["ollama", "proxyapi", "openai"]
        current_provider = (current_config or {}).get('provider', 'ollama')
        try:
            provider_index = providers.index(current_provider)
        except ValueError:
            provider_index = 0
        provider = st.selectbox(
            "–ü—Ä–æ–≤–∞–π–¥–µ—Ä —á–∞—Ç–∞", 
            providers, 
            index=provider_index, 
            key=f"{key_prefix}_provider"
        )
        
        if provider == "ollama":
            self._render_ollama_config(agent_instance, key_prefix)
        elif provider == "proxyapi":
            self._render_proxyapi_config(agent_instance, key_prefix)
        elif provider == "openai":
            self._render_openai_config(agent_instance, key_prefix)
    
    def _render_ollama_config(self, agent_instance, key_prefix: str):
        """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Ollama"""
        if self.available_ollama_models:
            # –ê–∫–∫—É—Ä–∞—Ç–Ω–æ –±–µ—Ä–µ–º —Ç–µ–∫—É—â—É—é –º–æ–¥–µ–ª—å –∏–∑ info, –Ω–µ —Ç—Ä–µ–±—É—è –ø–æ–ª–µ–π —ç–∫–∑–µ–º–ø–ª—è—Ä–∞
            info = {}
            try:
                info = agent_instance.get_chat_backend_info() or {}
            except Exception:
                info = {}
            current_model = info.get('model', self.available_ollama_models[0])
            selected_model = st.selectbox(
                "–ú–æ–¥–µ–ª—å Ollama:",
                self.available_ollama_models,
                index=self.available_ollama_models.index(current_model) if current_model in self.available_ollama_models else 0,
                key=f"{key_prefix}_ollama_model"
            )
            
            if st.button("–ü—Ä–∏–º–µ–Ω–∏—Ç—å Ollama", key=f"{key_prefix}_apply_ollama"):
                try:
                    # –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –∞–≥–µ–Ω—Ç—ã –Ω–µ –≤–æ–∑–≤—Ä–∞—â–∞—é—Ç bool ‚Äî —Å—á–∏—Ç–∞–µ–º —É—Å–ø–µ—Ö–æ–º –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –∏—Å–∫–ª—é—á–µ–Ω–∏—è
                    agent_instance.set_chat_backend("ollama", selected_model)
                    st.success(f"‚úÖ –ü—Ä–∏–º–µ–Ω–µ–Ω–æ: Ollama ‚Üí {selected_model}")
                    st.rerun()
                except Exception as e:
                    st.error(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        else:
            st.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π Ollama")
            st.info("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ Ollama —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏ –∑–∞–ø—É—â–µ–Ω")
    
    def _render_proxyapi_config(self, agent_instance, key_prefix: str):
        """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ProxyAPI"""
        col1, col2 = st.columns(2)
        
        with col1:
            base_url = st.text_input(
                "Base URL", 
                value=os.getenv("PROXYAPI_BASE_URL", "https://api.proxyapi.ru/openai/v1"), 
                key=f"{key_prefix}_proxyapi_base"
            )
            model = st.text_input(
                "–ú–æ–¥–µ–ª—å", 
                value=os.getenv("PROXYAPI_CHAT_MODEL", "gpt-4o"), 
                key=f"{key_prefix}_proxyapi_model"
            )
        
        with col2:
            api_key = st.text_input(
                "API Key", 
                type="password", 
                value=os.getenv("PROXYAPI_KEY", ""), 
                key=f"{key_prefix}_proxyapi_key"
            )
            temperature = st.slider(
                "–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞", 
                0.0, 1.0, 0.2, 0.1, 
                key=f"{key_prefix}_proxyapi_temp"
            )
        
        if st.button("–ü—Ä–∏–º–µ–Ω–∏—Ç—å ProxyAPI", key=f"{key_prefix}_apply_proxyapi"):
            try:
                agent_instance.set_chat_backend(
                    "proxyapi", model, base_url, api_key, temperature
                )
                st.success(f"‚úÖ –ü—Ä–∏–º–µ–Ω–µ–Ω–æ: ProxyAPI ‚Üí {model}")
                st.rerun()
            except Exception as e:
                st.error(f"‚ùå –û—à–∏–±–∫–∞: {e}")
    
    def _render_openai_config(self, agent_instance, key_prefix: str):
        """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è OpenAI"""
        col1, col2 = st.columns(2)
        
        with col1:
            model = st.text_input(
                "–ú–æ–¥–µ–ª—å", 
                value=os.getenv("OPENAI_CHAT_MODEL", "gpt-4o-mini"), 
                key=f"{key_prefix}_openai_model"
            )
            api_key = st.text_input(
                "API Key", 
                type="password", 
                value=os.getenv("OPENAI_API_KEY", ""), 
                key=f"{key_prefix}_openai_key"
            )
        
        with col2:
            temperature = st.slider(
                "–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞", 
                0.0, 1.0, 0.2, 0.1, 
                key=f"{key_prefix}_openai_temp"
            )
        
        if st.button("–ü—Ä–∏–º–µ–Ω–∏—Ç—å OpenAI", key=f"{key_prefix}_apply_openai"):
            try:
                agent_instance.set_chat_backend(
                    "openai", model, api_key=api_key, temperature=temperature
                )
                st.success(f"‚úÖ –ü—Ä–∏–º–µ–Ω–µ–Ω–æ: OpenAI ‚Üí {model}")
                st.rerun()
            except Exception as e:
                st.error(f"‚ùå –û—à–∏–±–∫–∞: {e}")
    
    def render_global_model_settings(self):
        """–û—Ç–æ–±—Ä–∞–∑–∏—Ç—å –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–µ–π"""
        st.subheader("üåê –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–µ–π")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**–ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è:**")
            st.code(f"""
USE_PROXYAPI={os.getenv('USE_PROXYAPI', 'false')}
PROXYAPI_KEY={'*' * 20 if os.getenv('PROXYAPI_KEY') else '–Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω'}
PROXYAPI_BASE_URL={os.getenv('PROXYAPI_BASE_URL', '–Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω')}
PROXYAPI_CHAT_MODEL={os.getenv('PROXYAPI_CHAT_MODEL', '–Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω')}
            """)
        
        with col2:
            st.markdown("**Ollama –º–æ–¥–µ–ª–∏:**")
            if self.available_ollama_models:
                for model in self.available_ollama_models[:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5
                    st.text(f"‚Ä¢ {model}")
                if len(self.available_ollama_models) > 5:
                    st.text(f"... –∏ –µ—â–µ {len(self.available_ollama_models) - 5}")
            else:
                st.warning("–ú–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        
        # –ö–Ω–æ–ø–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π
        if st.button("üîÑ –û–±–Ω–æ–≤–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π Ollama"):
            self.available_ollama_models = self._get_ollama_models()
            st.rerun()
    
    def render_agent_status(self, agents: Dict[str, any]):
        """–û—Ç–æ–±—Ä–∞–∑–∏—Ç—å —Å—Ç–∞—Ç—É—Å –≤—Å–µ—Ö –∞–≥–µ–Ω—Ç–æ–≤"""
        st.subheader("üìä –°—Ç–∞—Ç—É—Å –∞–≥–µ–Ω—Ç–æ–≤")
        
        for agent_name, agent_instance in agents.items():
            with st.expander(f"ü§ñ {agent_name}"):
                try:
                    config = agent_instance.get_chat_backend_info()
                    if config:
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("–ü—Ä–æ–≤–∞–π–¥–µ—Ä", config.get('provider', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'))
                        with col2:
                            st.metric("–ú–æ–¥–µ–ª—å", config.get('model', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'))
                        with col3:
                            temp = config.get('temperature', 'N/A')
                            st.metric("–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞", temp)
                    else:
                        st.warning("–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
                except Exception as e:
                    st.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞: {e}")
