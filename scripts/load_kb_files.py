#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ KB —Ñ–∞–π–ª–æ–≤ –≤ RAG —Å–∏—Å—Ç–µ–º—É
"""

import sys
import os
import json
import sqlite3
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –ø–∞–ø–∫—É –ø—Ä–æ–µ–∫—Ç–∞ –≤ –ø—É—Ç—å
sys.path.append(str(Path(__file__).parent.parent))

def load_kb_files_to_rag():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç KB —Ñ–∞–π–ª—ã –∏–∑ docs/kb/ –≤ RAG —Å–∏—Å—Ç–µ–º—É"""
    
    # –ü—É—Ç–∏
    kb_dir = Path("docs/kb")
    rag_db_path = "data/knowledge_bases/kbs.db"
    
    if not kb_dir.exists():
        print(f"‚ùå –ü–∞–ø–∫–∞ {kb_dir} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        return False
    
    if not Path(rag_db_path).exists():
        print(f"‚ùå –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö RAG {rag_db_path} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        return False
    
    # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
    conn = sqlite3.connect(rag_db_path)
    c = conn.cursor()
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ KB
        c.execute("SELECT id, name FROM knowledge_bases WHERE is_active = 1")
        kbs = c.fetchall()
        
        if not kbs:
            print("‚ùå –ù–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö –±–∞–∑ –∑–Ω–∞–Ω–∏–π")
            return False
        
        print(f"üìö –ù–∞–π–¥–µ–Ω–æ {len(kbs)} –∞–∫—Ç–∏–≤–Ω—ã—Ö –±–∞–∑ –∑–Ω–∞–Ω–∏–π:")
        for kb_id, kb_name in kbs:
            print(f"  - {kb_id}: {kb_name}")
        
        # –û—á–∏—â–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
        c.execute("DELETE FROM knowledge_documents")
        print("üßπ –û—á–∏—â–µ–Ω—ã —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º KB —Ñ–∞–π–ª—ã
        kb_files = list(kb_dir.glob("*.json"))
        print(f"üìÑ –ù–∞–π–¥–µ–Ω–æ {len(kb_files)} KB —Ñ–∞–π–ª–æ–≤")
        
        loaded_count = 0
        
        for kb_file in kb_files:
            print(f"\nüìñ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º {kb_file.name}...")
            
            try:
                # –ß–∏—Ç–∞–µ–º KB —Ñ–∞–π–ª
                with open(kb_file, 'r', encoding='utf-8') as f:
                    kb_data = json.load(f)
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é KB –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
                category = "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏"  # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                if "legacy_reglament" in kb_file.name:
                    category = "–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ä–µ–≥–ª–∞–º–µ–Ω—Ç—ã"
                elif "ui_" in kb_file.name:
                    category = "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏"
                
                # –ù–∞—Ö–æ–¥–∏–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é KB –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
                kb_id = None
                for db_kb_id, db_kb_name in kbs:
                    if category in db_kb_name:
                        kb_id = db_kb_id
                        break
                
                if not kb_id:
                    print(f"  ‚ö†Ô∏è  –ù–µ –Ω–∞–π–¥–µ–Ω–∞ –ø–æ–¥—Ö–æ–¥—è—â–∞—è KB –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ {category}")
                    continue
                
                # –°–æ–∑–¥–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
                title = f"KB: {kb_file.stem}"
                content = json.dumps(kb_data, ensure_ascii=False, indent=2)
                
                c.execute("""
                    INSERT INTO knowledge_documents 
                    (kb_id, title, file_path, content_type, file_size, upload_date, processed, processing_status, metadata)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    kb_id,
                    title,
                    str(kb_file),
                    "application/json",
                    len(content),
                    "2025-01-20T14:00:00",
                    1,  # processed
                    "completed",
                    json.dumps({"source": "kb_file", "original_file": str(kb_file)})
                ))
                
                # –°–æ–∑–¥–∞–µ–º —á–∞–Ω–∫–∏ –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞
                doc_id = c.lastrowid
                
                # –†–∞–∑–±–∏–≤–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –Ω–∞ —á–∞–Ω–∫–∏
                chunk_size = 1000
                chunks = []
                
                for i, item in enumerate(kb_data):
                    if isinstance(item, dict):
                        chunk_content = json.dumps(item, ensure_ascii=False)
                        if len(chunk_content) > chunk_size:
                            # –†–∞–∑–±–∏–≤–∞–µ–º –±–æ–ª—å—à–æ–π —á–∞–Ω–∫
                            for j in range(0, len(chunk_content), chunk_size):
                                chunk = chunk_content[j:j+chunk_size]
                                chunks.append({
                                    'content': chunk,
                                    'metadata': {
                                        'doc_id': doc_id,
                                        'chunk_index': len(chunks),
                                        'item_index': i,
                                        'title': item.get('title', f'Item {i}')
                                    }
                                })
                        else:
                            chunks.append({
                                'content': chunk_content,
                                'metadata': {
                                    'doc_id': doc_id,
                                    'chunk_index': len(chunks),
                                    'item_index': i,
                                    'title': item.get('title', f'Item {i}')
                                }
                            })
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —á–∞–Ω–∫–∏
                for chunk in chunks:
                    c.execute("""
                        INSERT INTO document_chunks 
                        (doc_id, chunk_index, content, metadata)
                        VALUES (?, ?, ?, ?)
                    """, (
                        doc_id,
                        chunk['metadata']['chunk_index'],
                        chunk['content'],
                        json.dumps(chunk['metadata'])
                    ))
                
                print(f"  ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {title} ({len(chunks)} —á–∞–Ω–∫–æ–≤)")
                loaded_count += 1
                
            except Exception as e:
                print(f"  ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {kb_file.name}: {e}")
                continue
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
        conn.commit()
        
        print(f"\nüéâ –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ {loaded_count} KB —Ñ–∞–π–ª–æ–≤ –≤ RAG —Å–∏—Å—Ç–µ–º—É!")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        c.execute("SELECT COUNT(*) FROM knowledge_documents")
        doc_count = c.fetchone()[0]
        
        c.execute("SELECT COUNT(*) FROM document_chunks")
        chunk_count = c.fetchone()[0]
        
        print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"  - –î–æ–∫—É–º–µ–Ω—Ç–æ–≤: {doc_count}")
        print(f"  - –ß–∞–Ω–∫–æ–≤: {chunk_count}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        conn.rollback()
        return False
    finally:
        conn.close()

if __name__ == "__main__":
    print("üöÄ –ó–∞–≥—Ä—É–∑–∫–∞ KB —Ñ–∞–π–ª–æ–≤ –≤ RAG —Å–∏—Å—Ç–µ–º—É...")
    success = load_kb_files_to_rag()
    
    if success:
        print("\n‚úÖ –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
        print("–¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å RAG —Å–∏—Å—Ç–µ–º—É –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –±–∞–∑–∞–º –∑–Ω–∞–Ω–∏–π.")
    else:
        print("\n‚ùå –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ—Ä—à–∏–ª–∞—Å—å —Å –æ—à–∏–±–∫–∞–º–∏.")
        sys.exit(1)
